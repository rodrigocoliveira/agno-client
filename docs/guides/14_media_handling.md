# 14. Media Handling

> **Prerequisites**: [01-05 Getting Started through Session Management](./01_getting_started.md)
> **Packages**: `@rodrigocoliveira/agno-client`, `@rodrigocoliveira/agno-react`

## Overview

This cookbook covers handling media content in messages, including images, video, and audio. Agno agents can generate or return media content that you need to display in your UI.

## Media Type Structures

```typescript
// Image data
interface ImageData {
  revised_prompt: string; // The prompt used to generate the image
  url: string;            // Image URL or base64 data URL
}

// Video data
interface VideoData {
  id: number;    // Video identifier
  eta: number;   // Estimated time of arrival (for async generation)
  url: string;   // Video URL
}

// Audio data (input)
interface AudioData {
  base64_audio?: string; // Base64 encoded audio
  mime_type?: string;    // e.g., 'audio/mp3', 'audio/wav'
  url?: string;          // Audio URL
  id?: string;           // Audio identifier
  content?: string;      // Text content / transcript
  channels?: number;     // Number of audio channels
  sample_rate?: number;  // Sample rate in Hz
}

// Response audio (generated by agent)
interface ResponseAudioData {
  id?: string;           // Audio identifier
  content?: string;      // Base64 audio content
  transcript?: string;   // Text transcript of the audio
  channels?: number;     // Number of audio channels
  sample_rate?: number;  // Sample rate in Hz
}

// Message with media
interface ChatMessage {
  role: 'user' | 'agent' | 'system' | 'tool';
  content: string;
  images?: ImageData[];
  videos?: VideoData[];
  audio?: AudioData[];
  response_audio?: ResponseAudioData;
  // ... other fields
}
```

## Core Client

### Checking for Media in Messages

```typescript
import { AgnoClient, ChatMessage } from '@rodrigocoliveira/agno-client';

const client = new AgnoClient({
  endpoint: 'http://localhost:7777',
  mode: 'agent',
  agentId: 'image-agent',
});

client.on('message:complete', (messages: ChatMessage[]) => {
  const lastMessage = messages[messages.length - 1];

  // Check for images
  if (lastMessage.images && lastMessage.images.length > 0) {
    console.log('Images received:', lastMessage.images.length);
    lastMessage.images.forEach((img, i) => {
      console.log(`Image ${i + 1}:`, img.url);
      console.log(`Prompt:`, img.revised_prompt);
    });
  }

  // Check for videos
  if (lastMessage.videos && lastMessage.videos.length > 0) {
    console.log('Videos received:', lastMessage.videos.length);
    lastMessage.videos.forEach((video, i) => {
      console.log(`Video ${i + 1}:`, video.url);
    });
  }

  // Check for audio
  if (lastMessage.audio && lastMessage.audio.length > 0) {
    console.log('Audio received:', lastMessage.audio.length);
  }

  // Check for response audio (agent-generated speech)
  if (lastMessage.response_audio) {
    console.log('Response audio:', lastMessage.response_audio.transcript);
  }
});
```

### Sending Media to Agent

```typescript
import { AgnoClient } from '@rodrigocoliveira/agno-client';

const client = new AgnoClient({
  endpoint: 'http://localhost:7777',
  mode: 'agent',
  agentId: 'vision-agent',
});

// Send an image file
async function sendImage(file: File) {
  const formData = new FormData();
  formData.append('message', 'What is in this image?');
  formData.append('file', file);
  await client.sendMessage(formData);
}

// Send from canvas/blob
async function sendCanvasImage(canvas: HTMLCanvasElement) {
  const blob = await new Promise<Blob>((resolve) =>
    canvas.toBlob((b) => resolve(b!), 'image/png')
  );

  const formData = new FormData();
  formData.append('message', 'Analyze this drawing');
  formData.append('file', blob, 'drawing.png');
  await client.sendMessage(formData);
}

// Send audio recording
async function sendAudioRecording(audioBlob: Blob) {
  const formData = new FormData();
  formData.append('message', 'Transcribe this audio');
  formData.append('file', audioBlob, 'recording.webm');
  await client.sendMessage(formData);
}
```

## React

### Rendering Images

```tsx
import { useAgnoChat } from '@rodrigocoliveira/agno-react';
import type { ImageData } from '@rodrigocoliveira/agno-types';

function MessageImages({ images }: { images: ImageData[] }) {
  const [selectedImage, setSelectedImage] = useState<ImageData | null>(null);

  return (
    <div className="message-images">
      <div className="image-grid">
        {images.map((img, index) => (
          <div key={index} className="image-item">
            <img
              src={img.url}
              alt={img.revised_prompt}
              onClick={() => setSelectedImage(img)}
              loading="lazy"
            />
            {img.revised_prompt && (
              <p className="image-prompt">{img.revised_prompt}</p>
            )}
          </div>
        ))}
      </div>

      {/* Lightbox modal */}
      {selectedImage && (
        <div className="lightbox" onClick={() => setSelectedImage(null)}>
          <img src={selectedImage.url} alt={selectedImage.revised_prompt} />
          <p>{selectedImage.revised_prompt}</p>
        </div>
      )}
    </div>
  );
}
```

### Rendering Videos

```tsx
import type { VideoData } from '@rodrigocoliveira/agno-types';

function MessageVideos({ videos }: { videos: VideoData[] }) {
  return (
    <div className="message-videos">
      {videos.map((video, index) => (
        <div key={index} className="video-item">
          {video.url ? (
            <video
              src={video.url}
              controls
              preload="metadata"
              className="video-player"
            >
              Your browser does not support video playback.
            </video>
          ) : (
            <div className="video-loading">
              <p>Video generating... ETA: {video.eta}s</p>
              <progress value={video.eta > 0 ? 50 : 100} max="100" />
            </div>
          )}
        </div>
      ))}
    </div>
  );
}
```

### Rendering Audio

```tsx
import type { AudioData, ResponseAudioData } from '@rodrigocoliveira/agno-types';

function MessageAudio({ audio }: { audio: AudioData[] }) {
  return (
    <div className="message-audio">
      {audio.map((item, index) => {
        const audioSrc = item.url || (item.base64_audio
          ? `data:${item.mime_type || 'audio/mp3'};base64,${item.base64_audio}`
          : null);

        return (
          <div key={index} className="audio-item">
            {audioSrc ? (
              <audio controls src={audioSrc}>
                Your browser does not support audio playback.
              </audio>
            ) : item.content ? (
              <p className="audio-transcript">{item.content}</p>
            ) : null}
          </div>
        );
      })}
    </div>
  );
}

function ResponseAudio({ audio }: { audio: ResponseAudioData }) {
  const audioSrc = audio.content
    ? `data:audio/mp3;base64,${audio.content}`
    : null;

  return (
    <div className="response-audio">
      {audioSrc && (
        <audio controls src={audioSrc} autoPlay={false}>
          Your browser does not support audio playback.
        </audio>
      )}
      {audio.transcript && (
        <p className="audio-transcript">{audio.transcript}</p>
      )}
    </div>
  );
}
```

### Complete Media Message Component

```tsx
import { useAgnoChat } from '@rodrigocoliveira/agno-react';
import type { ChatMessage } from '@rodrigocoliveira/agno-types';

function MessageContent({ message }: { message: ChatMessage }) {
  return (
    <div className="message-content">
      {/* Text content */}
      {message.content && (
        <div className="text-content">{message.content}</div>
      )}

      {/* Images */}
      {message.images && message.images.length > 0 && (
        <MessageImages images={message.images} />
      )}

      {/* Videos */}
      {message.videos && message.videos.length > 0 && (
        <MessageVideos videos={message.videos} />
      )}

      {/* Audio attachments */}
      {message.audio && message.audio.length > 0 && (
        <MessageAudio audio={message.audio} />
      )}

      {/* Agent-generated audio response */}
      {message.response_audio && (
        <ResponseAudio audio={message.response_audio} />
      )}
    </div>
  );
}

function Chat() {
  const { messages } = useAgnoChat();

  return (
    <div className="chat">
      {messages.map((msg, i) => (
        <div key={i} className={`message ${msg.role}`}>
          <MessageContent message={msg} />
        </div>
      ))}
    </div>
  );
}
```

### Image Upload Component

```tsx
import { useAgnoChat } from '@rodrigocoliveira/agno-react';
import { useState, useRef } from 'react';

function ImageUploadChat() {
  const { sendMessage, isStreaming } = useAgnoChat();
  const [previewUrl, setPreviewUrl] = useState<string | null>(null);
  const [file, setFile] = useState<File | null>(null);
  const [message, setMessage] = useState('');
  const fileInputRef = useRef<HTMLInputElement>(null);

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = e.target.files?.[0];
    if (selectedFile) {
      setFile(selectedFile);
      setPreviewUrl(URL.createObjectURL(selectedFile));
    }
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (isStreaming || !file) return;

    const formData = new FormData();
    formData.append('message', message || 'Analyze this image');
    formData.append('file', file);

    // Clean up preview
    if (previewUrl) URL.revokeObjectURL(previewUrl);
    setPreviewUrl(null);
    setFile(null);
    setMessage('');

    await sendMessage(formData);
  };

  const handleRemoveImage = () => {
    if (previewUrl) URL.revokeObjectURL(previewUrl);
    setPreviewUrl(null);
    setFile(null);
    if (fileInputRef.current) fileInputRef.current.value = '';
  };

  return (
    <form onSubmit={handleSubmit} className="image-upload-chat">
      {/* Image preview */}
      {previewUrl && (
        <div className="image-preview">
          <img src={previewUrl} alt="Preview" />
          <button type="button" onClick={handleRemoveImage}>
            Remove
          </button>
        </div>
      )}

      <div className="input-row">
        <button
          type="button"
          onClick={() => fileInputRef.current?.click()}
          disabled={isStreaming}
        >
          üì∑
        </button>
        <input
          ref={fileInputRef}
          type="file"
          accept="image/*"
          onChange={handleFileSelect}
          hidden
        />
        <input
          type="text"
          value={message}
          onChange={(e) => setMessage(e.target.value)}
          placeholder={file ? 'Add a message...' : 'Upload an image first'}
          disabled={isStreaming}
        />
        <button type="submit" disabled={isStreaming || !file}>
          Send
        </button>
      </div>
    </form>
  );
}
```

### Audio Recording Component

```tsx
import { useAgnoChat } from '@rodrigocoliveira/agno-react';
import { useState, useRef } from 'react';

function AudioRecordingChat() {
  const { sendMessage, isStreaming } = useAgnoChat();
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
        setAudioBlob(blob);
        stream.getTracks().forEach((track) => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('Failed to start recording:', error);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  const handleSubmit = async () => {
    if (!audioBlob || isStreaming) return;

    const formData = new FormData();
    formData.append('message', 'Process this audio');
    formData.append('file', audioBlob, 'recording.webm');

    setAudioBlob(null);
    await sendMessage(formData);
  };

  return (
    <div className="audio-recording-chat">
      {audioBlob && (
        <audio controls src={URL.createObjectURL(audioBlob)} />
      )}

      <div className="controls">
        {!isRecording && !audioBlob && (
          <button onClick={startRecording} disabled={isStreaming}>
            üéôÔ∏è Start Recording
          </button>
        )}

        {isRecording && (
          <button onClick={stopRecording} className="recording">
            ‚èπÔ∏è Stop Recording
          </button>
        )}

        {audioBlob && !isRecording && (
          <>
            <button onClick={handleSubmit} disabled={isStreaming}>
              Send Audio
            </button>
            <button onClick={() => setAudioBlob(null)}>
              Discard
            </button>
          </>
        )}
      </div>
    </div>
  );
}
```

## Key Points

- Messages can contain `images`, `videos`, `audio`, and `response_audio` arrays
- Media can be URLs or base64-encoded data
- Send media using `FormData` with file attachments
- Use `URL.createObjectURL()` for local file previews
- Clean up object URLs with `URL.revokeObjectURL()` to prevent memory leaks
- Check for media existence before rendering
- Handle loading states for async video generation (`eta` field)
- `response_audio` is specifically for agent-generated speech responses

## Next Steps

Continue to [15. Error Handling](./15_error_handling.md) to learn about error recovery and debugging.
